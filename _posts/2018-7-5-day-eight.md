After a day off for the Fourth of July, I'm back writing some photometry codes. I want to start by figuring out a more accurate way to detect sources in an image, and to do that I'm going to use aperture photometry. I'll make a new code in the NGC6819 repo's ["photometry codes"](https://github.com/GosnellResearchGroupSummer2018/NGC6819) folder called "aperture_photometry.py" that will more accurately subtract the background from an image than the [code](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/photometry%20codes/source_detection.py) I was using on [Tuesday](https://thom-ory.github.io/day-seven/). Also, instead of getting an image out, this code will save a text file to the desktop. This will actually be a very big first step that I think I'm close to completing; after today, if I'm able to do aperture photometry accurately, we'll have all the tools we need to get the data necessary to make color-magnitude diagrams. So, we should have that data by next week, and I can start writing a code that will draw HR-diagrams for us. If I am able to get all this done in a reasonable amount of time today, then I'll make a "master" code that will be called "accurate_source_detection.py" that will combine both previous codes; i.e., it will use aperture photometry to find the sources, save a text file to the desktop that gives information about those sources, and create an image that circles all sources in blue. 

## Coding
The first thing that I did was go back to [source_detection.py](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/photometry%20codes/source_detection.py) and try to make it run a little bit better. It was detecting way more sources in the image than were actually there because of noise, especially towards the edges. So, I restricted the field of view to only look at the center of the image, increased the radius of the aperture from 3 to 7 pixels, and bumped up the threshold required to be considered a source (sigma level went from 3 to 7 and flux threshold went from 5σ to 12σ). This is what I got compared to the raw data: 

![sources]({{thom-ory.github.io}}/images/sources_2.png) ![rawdata]({{thom-ory.github.io}}/images/rawdata_2.png) 

_This is the same field as yesterday, but we are looking at a smaller section. The original image was 5644x5895 pixels. I took the square, somewhat middle range of the image from 1250 ≤ x,y ≤ 3750 to use for source detection._

---
There's still an issue with the program reading really bright sources or sources that have a large angular size as multiple sources, but it's better than yesterday. However, while the program is generally correct, there are a few spots that are circled where I can't find a source in the raw data as well as a few spots I see in the raw data that aren't circled in the final image. Overall, I would call this test pretty unsuccessfull -- bad photometry. I decided to shrink the pixel range down even further to only 200x200, which is about the size of the images I've used for example exercises. This made everything different so I then went back to the original threshold level and aperture size. Now, looking at only 3000 ≤ x,y ≤ 3200, this is what I get: 

![sources_2]({{thom-ory.github.io}}/images/sources_3.png) ![rawdata_2]({{thom-ory.github.io}}/images/rawdata_3.png)

This looks a lot better. Remember, this is a reverse black and white image, so those white spots actually indicate an area of space that's not giving off any light, even though it looks like a star. Since this looks quite good, I would say the result of this test is learning that this code (and likely photutils itself) is much better suited to scanning small patches of the sky rather than that huge composite image. Still, there's the issue of reading larger sources as multiple sources. 

After this, I moved on to trying to figure out aperture photometry. 

## Aperture Photometry
In the [photutils reference material](https://photutils.readthedocs.io/en/stable/index.html) there are a few pages that seem really useful, like the ones on [aperture photometry](http://photutils.readthedocs.io/en/stable/aperture.html) and [background estimation](https://photutils.readthedocs.io/en/stable/background.html). Instead of diving into this code, I'm going to spend some time reading those. 

Looking at the page on background estimation, I'm interested in this `make_source_mask` function that photutils has. It seems like an accurate way to detect sources that's simpler than aperture photometry, though it might be more resource intensive and is likely less accurate. I'll add it to the beginning of [source_detection.py](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/photometry%20codes/source_detection.py), or make a new version, but it seems like worth looking in to. I also learned that "data values in the regions without coverage (usually zeros or NaNs) will adversely contribute to the background statistics" ([source](https://photutils.readthedocs.io/en/stable/background.html)), which explains why I was getting the errors yesterday when I was trying to detect sources over the entire image. There was some space where there was no data. Looking at a smaller region meant that I had no error messages. After finishing reading this page, there a few recursive methods of background subtraction i'm interested in exploring. It may seem like I should just choose the most accurate method of background subtraction and stick with it for the sake of time, but the main reason that I'm doing this research is for my own education and to learn how to do astronomy, so I want to learn as many methods of background subtractiona as possible. 

Reading the page on aperture photometry was also useful. I actually am not sure which of the methods I'm going to try will be most accurate. I'll test that soon by finding some data on a well known region of sky, running my own photometry on it, and comparing that to the "canon" photometry in astronomical literature. It does seem to me like aperture photometry would be susceptible to larger sources that still have light that is inside the annulus, making the background level seem higher than normal and giving a lower flux reading. However, I could do highly tailored photometry on single sources like X1 by inputing only one aperture object into the image and making its radius and the radius of the annulus around it exactly how big they need to be to give the best photometry data. 

# Conclusion
I unfortunately didn't get to be in the computational lab as much as I wanted today; I had been in for a few hours during the day but needed to finish a few things up after 6pm and had no access to the building. Luckily, most of what I wanted to do coud be done over the internet, so I did the reading and finished the blog post at home on my laptop. I wanted to work a little more on some code, but couldn't. Also, there were a few files on the desktop I use in the lab that I couldn't post on the [NGC6819 repo](https://github.com/GosnellResearchGroupSummer2018/NGC6819), but they'll be there in the morning. 

I feel like I'm ready to get deeper into photometry. I've just scratched the surface, but now I've achieved a few minor victories and can see where to dig in order to go deeper as effectively and quickly as possible. Tommorrow will be a battle between aperture photometry and these recursive methods. Hopefully next week we'll have an answer to which one is more accurate. Maybe, by the end of next week we'll have some useful data that will help us make conclusions about NGC6819. 

This morning, like all Mondays this summer, began with a meeting with Dr. G. We mostly went over what we had been doing last week, particularly on Friday since we had another meeting on Thursday. I mostly talked about the methods of photometry we've already tried and what we're planning on trying (tried: sigma clipping, source masking; to try: aperture, PSF). Dr. G had to yet again prevent me from getting ahead of myself, which I tend to do. So, I spent today working on aperture photometry before moving on to the more exciting-sounding point-spread-function photometry. I got some results!

## [aperture_photometry.py](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/photometry%20codes/aperture_photometry.py) (click to view code)  
It actually didn't take me too long to get an aperture photometry code that works. I like the math behind it; subtracting the background locally in the way that aperture photometry does is simple but powerful, like all the best math. One thing that took some figuring out in the begining was how to get the positions of where to put the apertures. I decided to use the same method I had been for source detection, which requires another estimate of the background. The difference is this time I'm only trying to get an estimate of the background noise so that I can determine which sources are significantly greater than the noise (significant when signal:noise ratio = 2:1). If I were to be doing sigma clipping as I was last week, I would just subtract the estimated background level I got from this estimation (the same function that gives noise also gives level). Instead, I go into about eight or twelve lines of math (depending on which lines you count as "math") that subtract the counts due to the background level away from the star's measured counts. [phot_table.txt](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/first_attempt_at_HST_source_detection/day_three/phot_table.txt) is what you get when you run the code. The coulmns are as follows : id, xposition, yposition, total counts in circle, total counts in annulus, background-subtracted counts in circle. I'm curious about the negatives in the last column; I'm not really sure what to make of them. I think most of the negatives are because of inaccuracies with this method. 

I actually tried two subtly different versions of the code. Line 21 in the code detects the sources in the image using whatever data you feed it, enabling you to then place the aperture objects in the right spots. I tried one way where I detected sources using all the data and another where I detected the sources after subtracting the rough estimate of the background from line 21. Really, this shouldn't change anything at all because, while line 21 outputs lots of information about the star including some rough estimates of counts, the only information I'm using at all from this line is x and y position data; the flux is determined by aperture photometry later on. It did make a slight difference in the overall results, but comparing only the last column of the two phot_tables generated from the two slightly different codes shows that the difference is ignorable, though. For almost all points, it's entirely negligible or literally nonexistent, though is significant for only few other points. Point 1's measured counts change from ~-3x10^-2 counts to ~-2x10^-2 counts, which is quite a bit of a bigger difference than any other other point I found. Overall, I don't think it really matters which technique we go with, especially because they should be identical in the first place. [phot_table_ybkg.txt](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/photometry%20codes/Comparisons_of_methods/phot_table_ybkg.txt)is the result without subtracting the background before source detection, while [phot_table_nbkg.txt](https://github.com/GosnellResearchGroupSummer2018/NGC6819/blob/master/photometry%20codes/Comparisons_of_methods/phot_table_nbkg.txt) contains the results when the background is subtracted before finding sources.  

![comparing_techiques]({{thom-ory.github.io}}/images/comparing_techniques.png)
![comparing_techniques_no_outlier]({{thom-ory.github.io}}/images/comparing_techniques_no_outlier.png)
_the last columns in phot_table_nbkg.txt and phot_table_ybkg.txt graphed against each other alongside the line y = x. Shows very good correlation -- nearly perfect, although this can't yet be fully determined because there are no error bars (I'll add them tomorrow). The second graph merely excludes the data point near (12,12)_ 

---
Along with the confusing negatives, which I still haven't really figured out, I'm also surprised at how small all these values are, especially compared to the practice examples I did. This is a lot less troubling to me than the negatives, though; the measured background level and noise in the example data I used were five and two respectively, whereas I measure the level and noise in the background of this image as 0.002 and 0.0053 respectively -- only a few orders of magnitude smaller. 

# Conclusion
I've felt up to this point point that I've known what I need to look up next, but I'm at the point where I'm starting to not know what I need to teach myself. I want to make this code better, but don't know what improvements to make. I feel like I need to learn more about the theory of photometry, although I also feel like I know what photometry is sort of well and how to do it somewhat successfully. I think I'm getting close to knowing everything I need to know for this particular project besides PSF photometry, although I know that's not true. There's an 80/20 rule I've heard that says it's easy to learn the first 80% percent of a subject and once you learn that you can do that thing as effectively as you'll ever need to. This first 80% is the basic "how to do it" of the thing and is about getting results, not doing it well. You have to do most things, like hobbies or chores, at 80% for your sanity, besides for what you do professionally. But, to be at a professional level, you have to learn like 95% of the subject or more, and learning anything past 80% is exponentially harder. It's more detail-oriented and is about why you can do somethinig at all and how to do it better, not just doing it.  Even though I'm not a professional astronomer, I want to do professional-level work since this is an actual paper that might get published. I have to learn the last 20%, and that's the hardest part, especially because those first 80 are easily and commonly taught so there's tutorials everywhere, but the last twenty require firsthand experience and creativity to learn. 

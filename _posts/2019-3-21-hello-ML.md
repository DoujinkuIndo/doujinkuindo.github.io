---
layout: post
title: Getting started with Machine Learning 
---

#### What is Machine Learning? 
It is a great topic to debate while drinking a beer. But apart from that, it is exacly what it sounds. Making a machine able to answer some questions/solve some problems.


#### What problems can be solved?

Things like classification, identification, projection, anomaly detection, noise reduction.

#### Classification 

One of the common application of ML is classification. Taken from Wikipedia:

>In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.

So I'll try to produce a kind of hello world in terms of ML classification algorithm.

#### Tools

Data Science currently evolves around a few programming languages (Python, R, Scala, Matlab) and ready made API from Amazon, Google, Microsoft and alike.

For this tutorial I will try to implement a classification algorithm using Python and the commonly used library [scikit](https://scikit-learn.org/stable/index.html). The installation requires other packages as well, so I found [Anaconda](https://www.anaconda.com/distribution/) as a ready to use platform.

~~As an editor I will use [Jupyter Notebook](https://jupyter.org/) whichis embedded in Anaconda and runs in your browser.~~  
Decided to use [Spyder](https://docs.spyder-ide.org/) instead, also bundled in Anaconda.

![Spyder screenshot](https://vladcozma.github.io/blog/images/hello-ml/hello-ml-02.jpg "Spyder")  




#### Problem

Given a set of messages and a set of categories, train the machine to output categories to new messages:

 | Message            | Category    |  
 | ------------------ | :---------: |  
 | I want a new car   |  shopping   |  

 | Message            | Category    |  
 | ------------------ | :---------: |  
 | I want speed       |  ?          |  
 

This will be a *supervised* classification, since I will first feed a data set with classifications already done from which it will learn to do new ones. Therefore I used two datasets. ```training-dataset.csv``` and ```validation-dataset.csv```. After training the model with the training dataset I would expect it will produce de same labels found in the validation dataset. that is because 
> Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. { https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation}.

In case you only have one dataset, you can manually split it in two, or use 
```python
from sklearn.model_selection  import train_test_split
# this method split one dataset into train set and validation set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33) 
``` 
	
And you will have two datasets, train and test. Playing with the parameters will give you different accuracy levels.


##### Step 1 - loading data

I found a library, [Pandas](http://pandas.pydata.org/), which provides data analysis structures and tools

```python
 import pandas as pd
 trainset = pd.read_csv("training-dataset.csv",sep=";")
 print('Training dataset loaded. Description below:\n')
 trainset.info()
 print('\n')
```

```
Training dataset loaded. Description below:

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 889 entries, 0 to 888
Data columns (total 3 columns):
Message                 889 non-null object
Additional Condition    889 non-null object
Label                   889 non-null object
dtypes: object(3)
memory usage: 20.9+ KB
```
I loaded the training dataset in a pandas dataset type (basically a matrix). Same goes for validation set.

##### Step 2 - creating an estimator

Wikipedia [says](https://en.wikipedia.org/wiki/Estimator) an estimator is a rule to calculate an output based on an input. 

In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T).

The accuracy of your estimation highly depends on the chosen estimator. And the choice of estimator depends on the type and size of the problem. scikit-learn has some estimators embedded, as seen in the comparation found on [scikit](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) and looks like  

![Classification methods](https://vladcozma.github.io/blog/images/hello-ml/hello-ml-03.jpg "Classification")  


``python

from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
``


Training
```
# train method
def train(classifier, X, y):

    classifier.fit(trainset.Message, trainset.Label)
    print("Accuracy: %s" % classifier.score(validationset.Message, validationset.Label))
    return classifier
```









bag of words


Referrences:  

+ https://scikit-learn.org

+ https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a


+ https://nlpforhackers.io/text-classification/
	



Now that dolphot is working, most of the day is spent just waiting for it to run. I've decided the thing that was troubling me before (the fact that when using `splitgroups` on a drc image one of the extensions fails to write properly) isn't actually an issue because I'm not using that extension anywhere in the actual photometry. 

# Running dolphot
This takes awhile. As of today, I am finished running `wfc3mask` and `splitgroups` on all the images I need to. I've also run `calcsky` on the first four folders. `calcsky` takes a lot longer to run than the other preprocessing steps; not only does it take about 1-2 minutes to run (as opposed to about a second), I have to do it one at a time, where as with the other two I can use `*_flc.fits` and perform the command on all files in the folder. 

The big command, `dolphot`, takes somewhere from 3-5 hours to run on my laptop, but I can run the photometry on three folders at once. With 3 instances of `dolphot` running, I'm using about 85% of my CPU during the most resource intensive parts, and no more than 60% of my RAM. After today, I will have good results for three folders and bad results for the first folder. I accidentally put the same file name twice in the parameter file for the first folder so have duplicate results for one image and no results for another. Since dolphot's output has the photometry for each image so well mixed-together, I think it will be best for future coding to re-run the photometry for that folder. 

# Conclusion
I've turned my attention to understanding dolphot's output and thinking of ways to use it to generate color magnitude diagrams. Python should be able to handle this job pretty easily. I feel like I know what's going on in dolphot's output, but it's an overwhelming amount of data, and I'm not entirely sure what's relevant at this point. I think Thursday's meeting with Dr. G will help me figure out what all this data means, but I can tackle some of the basic coding stuff for now. 

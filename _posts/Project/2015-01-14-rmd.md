---
layout: post
title: Rmd to md test
---

# EDPSY 558 SEM Homework3
Chungil Chae  
November 12, 2014  

Use the raw data (MEARLI.csv) for this assignment. Missing code = -99999. The data file contains data from preschool (3- and 4-year old) children on the following variables:

ID: arbitrary ID number.
AGE: age of child in years.
CA (Counting Aloud): “count aloud as high as they can,” and performance is based on the total of numbers stated in correct sequence, beginning with the number 1.
M (Measurement): identify fundamental measurement concepts (e.g., taller, shorter, higher,
lower) using basic shapes.
CO (Counting Objects): count sets of objects and correctly identify the total number of
objects in the set.
NN (Number Naming): read individual numbers (or shapes) in isolation and rapidly identify
the specific number (shape) being viewed.
PR (Pattern Recognition): identify patterns using short sequences of basic shapes (i.e., circle,
square, and triangle).
G (Grouping): recognize the number of shapes in a small set.

Select variables from CA to G, which are Item Response Theory (IRT) scaled scores, that are supposed to be indicators of latent Math ability. Answer the questions and support your answers with relevant numerical results from your analyses.

#0. Data Prepareation
##Load Data

```r
MEARLI <- read.csv("~/Documents/coding/R/Class/EDPSY558/assignment3/MEARLI.csv", header=FALSE)
colnames(MEARLI) <- c("ID", "AGE", "CA", "M", "CO", "NN", "PR", "G")
```



##dataset

```r
data0<-MEARLI
```



##Missing coding

```r
colnames(data0) <- c("ID", "AGE", "CA", "M", "CO", "NN", "PR", "G")
data0$CA <- ifelse( data0$CA == -99999, NA, data0$CA)
data0$M <- ifelse( data0$M == -99999, NA, data0$M)
data0$CO <- ifelse( data0$CO == -99999, NA, data0$CO)
data0$NN <- ifelse( data0$NN == -99999, NA, data0$NN)
data0$PR <- ifelse( data0$PR == -99999, NA, data0$PR)
data0$G <- ifelse( data0$G == -99999, NA, data0$G)
```



##Multiple Imputation

```r
require(mice)
```

```
## Loading required package: mice
## Loading required package: Rcpp
## Loading required package: lattice
## mice 2.22 2014-06-10
```

```r
md.pattern(data0)
```

```
##     ID AGE CA  M CO NN PR  G    
## 254  1   1  1  1  1  1  1  1   0
##  90  1   1  0  0  0  0  0  0   6
##      0   0 90 90 90 90 90 90 540
```

```r
p <- md.pairs(data0)
p
```

```
## $rr
##      ID AGE  CA   M  CO  NN  PR   G
## ID  344 344 254 254 254 254 254 254
## AGE 344 344 254 254 254 254 254 254
## CA  254 254 254 254 254 254 254 254
## M   254 254 254 254 254 254 254 254
## CO  254 254 254 254 254 254 254 254
## NN  254 254 254 254 254 254 254 254
## PR  254 254 254 254 254 254 254 254
## G   254 254 254 254 254 254 254 254
## 
## $rm
##     ID AGE CA  M CO NN PR  G
## ID   0   0 90 90 90 90 90 90
## AGE  0   0 90 90 90 90 90 90
## CA   0   0  0  0  0  0  0  0
## M    0   0  0  0  0  0  0  0
## CO   0   0  0  0  0  0  0  0
## NN   0   0  0  0  0  0  0  0
## PR   0   0  0  0  0  0  0  0
## G    0   0  0  0  0  0  0  0
## 
## $mr
##     ID AGE CA M CO NN PR G
## ID   0   0  0 0  0  0  0 0
## AGE  0   0  0 0  0  0  0 0
## CA  90  90  0 0  0  0  0 0
## M   90  90  0 0  0  0  0 0
## CO  90  90  0 0  0  0  0 0
## NN  90  90  0 0  0  0  0 0
## PR  90  90  0 0  0  0  0 0
## G   90  90  0 0  0  0  0 0
## 
## $mm
##     ID AGE CA  M CO NN PR  G
## ID   0   0  0  0  0  0  0  0
## AGE  0   0  0  0  0  0  0  0
## CA   0   0 90 90 90 90 90 90
## M    0   0 90 90 90 90 90 90
## CO   0   0 90 90 90 90 90 90
## NN   0   0 90 90 90 90 90 90
## PR   0   0 90 90 90 90 90 90
## G    0   0 90 90 90 90 90 90
```

```r
imp <- mice(data0, seed = 23109)
```

```
## 
##  iter imp variable
##   1   1  CA  M  CO  NN  PR  G
##   1   2  CA  M  CO  NN  PR  G
##   1   3  CA  M  CO  NN  PR  G
##   1   4  CA  M  CO  NN  PR  G
##   1   5  CA  M  CO  NN  PR  G
##   2   1  CA  M  CO  NN  PR  G
##   2   2  CA  M  CO  NN  PR  G
##   2   3  CA  M  CO  NN  PR  G
##   2   4  CA  M  CO  NN  PR  G
##   2   5  CA  M  CO  NN  PR  G
##   3   1  CA  M  CO  NN  PR  G
##   3   2  CA  M  CO  NN  PR  G
##   3   3  CA  M  CO  NN  PR  G
##   3   4  CA  M  CO  NN  PR  G
##   3   5  CA  M  CO  NN  PR  G
##   4   1  CA  M  CO  NN  PR  G
##   4   2  CA  M  CO  NN  PR  G
##   4   3  CA  M  CO  NN  PR  G
##   4   4  CA  M  CO  NN  PR  G
##   4   5  CA  M  CO  NN  PR  G
##   5   1  CA  M  CO  NN  PR  G
##   5   2  CA  M  CO  NN  PR  G
##   5   3  CA  M  CO  NN  PR  G
##   5   4  CA  M  CO  NN  PR  G
##   5   5  CA  M  CO  NN  PR  G
```

```r
print(imp)
```

```
## Multiply imputed data set
## Call:
## mice(data = data0, seed = 23109)
## Number of multiple imputations:  5
## Missing cells per column:
##  ID AGE  CA   M  CO  NN  PR   G 
##   0   0  90  90  90  90  90  90 
## Imputation methods:
##    ID   AGE    CA     M    CO    NN    PR     G 
##    ""    "" "pmm" "pmm" "pmm" "pmm" "pmm" "pmm" 
## VisitSequence:
## CA  M CO NN PR  G 
##  3  4  5  6  7  8 
## PredictorMatrix:
##     ID AGE CA M CO NN PR G
## ID   0   0  0 0  0  0  0 0
## AGE  0   0  0 0  0  0  0 0
## CA   1   1  0 1  1  1  1 1
## M    1   1  1 0  1  1  1 1
## CO   1   1  1 1  0  1  1 1
## NN   1   1  1 1  1  0  1 1
## PR   1   1  1 1  1  1  0 1
## G    1   1  1 1  1  1  1 0
## Random generator seed value:  23109
```

```r
complete(imp)
```

```
##      ID AGE       CA        M       CO      NN       PR      G
## 1     1   3  0.52104  1.17472  1.05176  0.3856  0.83018  0.925
## 2     2   3  4.02620  1.59710  4.05383  6.7329  2.76609  2.678
## 3     3   3  0.91508  0.94462  1.82684  0.8123  0.39705  0.697
## 4     4   3  0.12617  0.95135 -0.61009 -0.2703  0.51878 -0.286
## 5     5   3  1.11369  1.04027  0.63041  0.6375  0.32809  0.221
## 6     6   3 -0.62886  1.10969  0.70239  0.2824  0.57464  0.620
## 7     7   3  0.91941 -1.78667 -0.61009  0.3856 -2.07511 -0.415
## 8     8   3  1.48268  1.40008 -0.61009  0.8123  1.36754  0.345
## 9     9   3  2.10046  1.17472  2.10725  2.0020  0.51878  0.081
## 10   10   3  0.91941  1.10969  0.63041  1.7533  0.54574 -0.574
## 11   11   3  0.92285  1.17215  0.63041  0.8123  0.49235  0.656
## 12   12   3 -0.06008  0.09643 -0.94416 -2.5252 -2.07511 -1.152
## 13   13   3  0.91941  0.83203  0.63041  0.4996 -0.75329  0.284
## 14   14   3  1.09931  0.41749 -0.94416  0.1676 -2.07511 -0.792
## 15   15   3  1.50815  1.10969 -0.94416  0.4996 -2.07511  0.221
## 16   16   3 -0.62886  1.10969  0.63041  0.8123  1.06914  0.003
## 17   17   3 -0.06008  1.10969  0.48381  2.1967  0.49235  0.403
## 18   18   3  1.11369  1.17472  0.63041  2.2766  0.45912  0.672
## 19   19   3  0.76758  0.41749  0.89593  2.2766  0.54500 -0.250
## 20   20   3  2.49535  1.10969  1.24691  3.7628  0.51878  0.620
## 21   21   3  0.91508  0.95135  0.75550  1.2477  0.49235  0.568
## 22   22   3 -1.13983 -2.12861 -0.94416 -2.5252 -2.07511 -1.152
## 23   23   3 -1.13983 -2.12861 -0.94416 -2.5252 -2.07511 -1.152
## 24   24   3 -0.61744  1.14217  0.98473 -0.9678  0.46154  0.876
## 25   25   3  2.10049  1.10969  3.23102  3.5607  0.21482  2.012
## 26   26   3 -0.06008  0.95135 -0.61009  1.4466  0.09249  0.460
## 27   27   3  0.91508  0.44300  0.82367  1.4466  0.49000  0.656
## 28   28   3  1.11369  1.17472  0.89593  0.4996  0.58379  0.925
## 29   29   3  0.91941  0.95135  0.75550  1.2477  0.54574  0.003
## 30   30   3  1.90306  1.25756  5.13507  3.7132  2.78846  1.364
## 31   31   3  0.12190  0.68685 -0.94416  0.3856  1.36754 -0.574
## 32   32   3 -1.13983 -2.12861 -0.94416  0.2824 -2.07511  0.153
## 33   33   3  0.91508  0.23475  0.63041  4.2186  0.49235  0.672
## 34   34   3  2.10046  0.95135  1.05176  1.7533  0.49235  0.460
## 35   35   3  0.91941  1.25756  1.24691  1.7533  0.49235  0.672
## 36   36   3  0.92285  0.52761  0.89593  1.7533  2.90378  1.131
## 37   37   3  0.76758  1.10969  1.05176  1.8832  0.58379  1.244
## 38   38   3  0.91508  1.63422  2.24008  3.8215  1.24969  2.012
## 39   39   3  1.22880  1.04027  0.75550  1.6113  0.51878  0.925
## 40   40   3  1.11369  0.54119  0.05155  0.4996  0.32809  0.568
## 41   41   3 -0.61744 -2.31222  0.67293  1.0245 -2.07511 -1.167
## 42   42   3  0.91508  1.10969  1.55787  1.4466  0.58379  0.824
## 43   43   3  1.09931 -2.12861  0.48381  0.4996 -0.12928 -0.177
## 44   44   3  0.91508  1.63422  0.63041  0.8123 -0.12928  0.925
## 45   45   3  0.12617  0.16204  0.42264  0.7384  1.36754  1.290
## 46   46   3  1.09931  0.67432  0.98473  1.2477  0.18186  1.349
## 47   47   3  1.11369  0.97754  1.24691  2.5241  1.83299  0.790
## 48   48   3  1.11369  0.52848  0.42264  0.0293  0.65588  0.697
## 49   49   3  0.91508  0.27712  1.06580  0.2824  0.65588  0.835
## 50   50   3  0.52481  0.30754  0.63041  2.3944  0.30576  0.470
## 51   51   3  0.52104  0.15317  0.82367  0.1676  0.30576 -0.384
## 52   52   3  1.11369  0.68685  0.75550  0.4491  0.18186 -0.241
## 53   53   3  0.91508  0.94462  0.98473  0.3856 -2.03855 -1.167
## 54   54   3  0.12617  0.30754  0.42264  0.2824 -1.21148 -1.167
## 55   55   3  0.91941 -2.13105  2.27759  3.4755  0.45380  1.053
## 56   56   3  0.91508  0.94462  1.17040  3.7132  2.90378  1.896
## 57   57   3  0.12617  0.52848  0.98473  0.3856  0.49000 -0.015
## 58   58   3  1.11403  1.10969  1.61888  1.2983  0.39705  1.244
## 59   59   3  0.12617  0.40599  0.42264  0.3856  0.54500  0.697
## 60   60   3  4.02620  1.59710  1.76955  4.0414  0.25343  1.044
## 61   61   3  0.91318  0.52761  1.05176  3.1390  0.51878  1.791
## 62   62   3  0.76758  0.40599  0.82367  0.8123  1.04384  0.242
## 63   63   3  2.08378  0.40599  0.98473  0.8123  2.90378  0.876
## 64   64   3  0.91508  0.40599  0.82367  0.3856  0.54500  0.876
## 65   65   3  1.10613  0.37804  0.99388  2.9478  1.54484  1.205
## 66   66   3  0.91941  1.17215  0.98473  2.0020  1.26185 -0.499
## 67   67   3  0.52481  1.03596  2.98612  0.8123  1.33147  1.349
## 68   68   3  1.09931  0.52848  0.67293  1.4466  0.18186  0.315
## 69   69   3  0.12190  0.30754  0.42264  0.2824  0.51768  0.636
## 70   70   3 -0.36892  0.67432  0.77927  0.3856  0.54500  0.190
## 71   71   3  0.16112  0.32265  1.24691  2.1967  0.53350  1.925
## 72   72   3  0.52104  0.67432  0.67293  0.2824  0.49000  0.994
## 73   73   3  1.50813  1.25756  1.25568  2.0986  2.76609  1.205
## 74   74   3  1.22880  1.40008  1.05176  1.7562 -0.23622  0.384
## 75   75   3  0.71711  0.98740  0.70239  3.3617 -0.93074  1.112
## 76   76   3  1.11403  1.26317  0.99388  3.5656  0.63826  0.895
## 77   77   3  0.91508  0.15317  1.18890  0.3214  0.49000  0.345
## 78   78   3  0.12617  0.52848  0.42264  0.9327  1.36754  0.925
## 79   79   3  0.12190  0.44300 -0.68582  0.1676  0.32860  0.284
## 80   80   3 -0.19183  0.52848  0.42264  0.1676  0.51768  0.315
## 81   81   3  2.10046  0.52848  1.82684  1.7533  2.90378  0.994
## 82   82   3  0.91941  0.67432  0.98473  1.4466  0.18186  0.935
## 83   83   3  0.91941  1.17215  2.08759  0.8123  1.42670  0.384
## 84   84   3  0.91941  1.03596  0.82367  0.8123  0.51768  0.935
## 85   85   3  0.12190  0.82199  1.45050  2.0020  0.49000  0.079
## 86   86   3  1.09931  0.41749  1.05176  1.0245  0.54574  0.774
## 87   87   3  0.52481  0.22526  0.42264  1.0245  0.05434 -0.384
## 88   88   3  0.12617  0.30754  0.98473  0.3856  0.65588 -0.015
## 89   89   3  1.09931  1.10667  2.60419  2.2766  2.90378  2.421
## 90   90   3  1.70549  0.94462  0.67293  1.8832  1.04384  1.112
## 91   91   3  0.91508  0.67432  0.82367  2.0020  1.83299  1.471
## 92   92   3  0.12617  0.67432  0.42264  0.4996  0.49000  0.164
## 93   93   3  0.12190  0.40599  1.45050  0.3856  0.30576  0.315
## 94   94   3 -0.06008  1.10667  0.67293  0.3856  0.45380  0.636
## 95   95   3  2.10511  1.59710  2.29092  1.2983  0.91393  1.925
## 96   96   3 -0.62886  0.30754  0.82367  0.4996 -0.06814  0.079
## 97   97   3  0.91941  0.15317  0.82367  2.1070  0.30576  1.112
## 98   98   3  0.12190  0.15317  0.67293  0.3856 -2.03855 -1.167
## 99   99   3  0.12617  1.03596  0.82367  0.2824  0.18186 -0.241
## 100 100   3  0.52481  0.30754  0.67293  0.3856  0.18186  0.697
## 101 101   3  1.50873  0.52848  1.82684  2.1967  1.83299  0.994
## 102 102   3  0.12190  0.30754  0.42264  0.1676  0.51768 -1.167
## 103 103   3  0.71711  1.14217  2.06578  1.4471  0.14431  1.925
## 104 104   3  0.70549  1.17215  0.98473  1.7533  0.54500  0.935
## 105 105   3  0.70549  1.17215  2.08759  1.7533  1.54484  1.290
## 106 106   3  0.91941  0.08803  1.17040  1.2477  0.49000  1.290
## 107 107   3  0.12190  0.22526 -0.43545  0.4996 -2.03855 -1.167
## 108 108   3  0.91318  0.44300  0.75550  3.4755 -0.23622  1.385
## 109 109   3  0.91508  0.94462 -0.43545  0.4996  0.49000  0.876
## 110 110   3  1.48268  0.22526  2.60419  1.6113  0.39705  0.994
## 111 111   3  1.11369  1.10969 -0.27061  2.6532  2.76609  0.533
## 112 112   3  0.91508  0.95135  0.75550  1.0245  0.21482  0.620
## 113 113   3  1.09931  0.23475  1.05176  2.1967 -2.07511  2.516
## 114 114   3 -0.36892  0.16204  0.05155  1.0245 -2.07511  0.081
## 115 115   3  0.52481  0.68685  0.48381  0.2824  0.45912  0.976
## 116 116   3  0.76758  1.10667  1.45050  0.6375  0.49000  1.112
## 117 117   3  0.91941  0.95135  2.10725  0.9327  1.83299  1.044
## 118 118   3 -0.19183  0.83203  0.89593  0.8123  0.09249  1.028
## 119 119   3  2.10511  0.98740  2.84597  1.9283  0.53350  1.044
## 120 120   3  2.49535  1.03596  0.63041  0.2824  0.54500  0.164
## 121 121   3  0.12190  0.08803  0.67293  0.1676  1.04384 -0.015
## 122 122   3  0.12190  0.30754  0.77927  1.5953  0.49000  1.249
## 123 123   3 -1.13983  0.67432  0.67293  0.4996  0.49000  0.315
## 124 124   3  0.91941  1.10667  0.98473  0.6375  1.54484  1.112
## 125 125   3 -1.13983 -1.78667 -0.94416  0.3214 -2.07511  0.304
## 126 126   3  0.52104  1.17215  2.08759  1.7533  1.54484  1.112
## 127 127   3  2.10046  1.10667  3.14710  2.1070  1.54484  1.290
## 128 128   3  0.52481  0.52848  0.82367  0.3856  0.54500  0.242
## 129 129   3  0.16112  1.40008  2.03379  1.2477  2.76609  0.790
## 130 130   3  0.91941  0.01854  0.67293  0.2824  0.30576  0.450
## 131 131   3  0.12190  0.52848  0.98473  0.4996  0.45380  0.450
## 132 132   3 -0.06008  0.95135  0.67293  0.4996  0.57464  1.097
## 133 133   3  7.62857  1.62943  3.14710  7.1778  2.90378  2.714
## 134 134   3  0.12617  0.95135  0.63041  1.4466  0.49235  0.568
## 135 135   3  1.22880  1.87322  0.63041  1.6113  0.51878  1.028
## 136 136   3  0.12190  1.04027  0.75550  2.0020 -0.12928  0.403
## 137 137   3  0.92285  0.27080  2.08759  1.4466  1.54484  1.925
## 138 138   4  2.10047  1.59710  1.82326  3.3617  2.76609  2.678
## 139 139   4  7.62857  2.16129  4.29447  6.7329  0.49888  2.678
## 140 140   4  4.02620  2.62612  2.70631  4.1443  2.76609  2.678
## 141 141   4  2.49535  1.59710  3.00487  4.0414  2.02749  2.678
## 142 142   4  0.73621  0.65645 -0.19318  2.2547  0.53350  0.105
## 143 143   4  2.10047  1.47470  1.61888  1.2983  1.39730  0.105
## 144 144   4  1.70557  2.16129  1.82326  1.7562  2.76609  0.241
## 145 145   4  2.49535  1.79703  2.06578  2.3944  0.41301  2.678
## 146 146   4  0.92285 -2.31222 -0.57007  0.9327 -1.23243  0.304
## 147 147   4  0.92285  1.26749  0.89539  1.1288  2.76609  1.044
## 148 148   4  7.23371  1.47470  1.61888  3.9152  2.76609  2.066
## 149 149   4  0.71711  1.14217  1.06580  1.4471 -0.93074  0.477
## 150 150   4  0.11237  1.47470  1.44201  2.3944  0.14431  1.044
## 151 151   4  1.10613  1.37306 -0.43545  1.1288 -0.12928  0.697
## 152 152   4  2.49535  1.59710  1.61888  1.1288  1.11512  1.523
## 153 153   4  2.10047  1.37306  1.25568  0.7384  1.26185  0.688
## 154 154   4  1.50813  0.45037  1.06580  0.4491 -1.23243  0.364
## 155 155   4  2.10047  0.45037  0.70239  0.3214 -1.23243  0.585
## 156 156   4  1.11403  1.47470  0.70239  2.0986 -1.23243 -0.250
## 157 157   4  1.10613  0.64546  2.03379  1.9283  1.34276  0.533
## 158 158   4  0.73621  0.97754  0.99388  1.9283  0.91393  0.954
## 159 159   4  2.49535  1.79703  1.61888  1.2983  2.90378  1.205
## 160 160   4  0.92285  1.14217  0.63041  1.2983 -0.93074  0.876
## 161 161   4  2.49535  1.79703  2.29092  2.5241  2.76609  1.791
## 162 162   4  1.11403  0.97754  1.38433  1.7562  0.63617  1.619
## 163 163   4  1.90210  2.62444  2.06578  5.1640  0.49888  1.364
## 164 164   4  2.49535  0.38453  1.82326  2.6532  0.46154 -1.009
## 165 165   4  2.49535  1.47470  2.70631  1.9283 -0.93074  1.262
## 166 166   4  0.92285  0.64546  1.38433  1.4471  0.51878  0.266
## 167 167   4  0.91318  1.79703  1.44201  2.0986 -0.01277  2.678
## 168 168   4  0.71711 -2.12861 -0.94416  0.3856  0.57373 -0.286
## 169 169   4  0.92285  0.53659  0.70239  0.0293 -0.93074  0.688
## 170 170   4  2.10049  1.59710  1.56609  2.5241  2.76609  1.896
## 171 171   4  2.49535  2.16129  1.82326  2.5241  2.76609  2.678
## 172 172   4  0.92285  0.98740  1.06580  0.4491  0.57464  0.105
## 173 173   4  0.91318  2.62612  2.29092  1.5953  2.76609  2.678
## 174 174   4  0.73621  1.14217  1.06580 -0.9678 -1.23243 -0.371
## 175 175   4  1.47114  0.98740  1.44201  0.5775  0.57464  0.304
## 176 176   4  2.49535  0.80243  2.60048  3.9152  0.49888  2.012
## 177 177   4  1.10613  0.53659  1.44201  3.8589  2.02749  2.678
## 178 178   4  4.02620  1.47470  4.29447  3.7950  2.02749  2.678
## 179 179   4  1.25590  2.16129  1.82326  2.9478  1.11512  1.690
## 180 180   4  0.91941  0.95135  1.76955  0.4996 -0.93074  0.697
## 181 181   4  2.10047  2.62612  4.05383  1.9283  1.59642  2.284
## 182 182   4  2.49535  2.16129  2.06578  3.1390  2.02749  2.066
## 183 183   4  1.25590  1.47470  1.25568  5.1640  2.76609  2.678
## 184 184   4  1.11403  0.38453  0.89539  4.5405  0.53350  1.322
## 185 185   4  3.48457  2.16129  2.29092  4.1443  1.59642  2.678
## 186 186   4  0.92285  0.53659 -0.19318  0.4491  0.46154  0.531
## 187 187   4  0.11237  1.14217 -0.40473  0.7384  0.14431 -1.009
## 188 188   4  0.92285  1.47470  2.06578  1.4471  2.76609  1.690
## 189 189   4  1.11403  1.47226  1.44201  2.5241  2.81587  1.760
## 190 190   4  2.08652  1.26749  0.70239  2.2547  2.76609  1.205
## 191 191   4  2.10047  1.37306  1.44201  0.9327 -1.23243  1.097
## 192 192   4  1.11403  1.14217  1.25568  0.5775  2.76609 -0.250
## 193 193   4  2.10511  0.81420  0.98473  3.7628  0.53350  2.289
## 194 194   4  0.91318  1.26749  1.44201  2.0986  1.11512  1.385
## 195 195   4 -0.61744  0.27712 -0.40473  0.7384  0.49888  0.175
## 196 196   4  2.10511  1.59710  2.06578  3.7064  2.76609  2.678
## 197 197   4  0.92285  1.47470  1.44201  2.0986  2.76609  2.678
## 198 198   4  0.11237 -2.13105 -0.48506  0.3856 -2.07511  0.221
## 199 199   4  2.10511  2.16129  2.70631  3.9152  2.76609  2.678
## 200 200   4  7.62857  2.16129  1.06580  6.7329  2.76609  2.284
## 201 201   4  0.92285  0.44300  0.82367  0.4996  0.45912  1.290
## 202 202   4  0.71711  0.44300  0.77927  1.1288  0.40414  0.656
## 203 203   4  1.11403  1.37005  0.99388  1.9283  2.81587  1.760
## 204 204   4  0.71711  1.37306  1.25568  1.7562 -1.23243  0.241
## 205 205   4  1.47114  1.37005  2.60048  2.0986  0.91393  1.131
## 206 206   4  2.49532  1.37005  1.18890  2.9478  1.47470  1.925
## 207 207   4  2.49535  1.37005  2.31886  3.1390  2.13933  0.017
## 208 208   4  1.25590  1.37306  1.61888  2.9478 -0.01277  0.688
## 209 209   4  2.28716  2.62444  2.99968  3.7064  0.63617  1.687
## 210 210   4  0.11237  0.44300  0.99388  1.2983  0.45707  0.533
## 211 211   4  1.31183  1.37005  1.56609  0.4491  1.69413  0.656
## 212 212   4 -0.85401  0.52761 -0.68582 -1.9956  2.81587 -1.021
## 213 213   4  1.11403  1.47226  2.31886  2.3944  0.63617  1.838
## 214 214   4  2.10511  1.79703  4.05383  2.0986  2.02749  2.678
## 215 215   4  2.10047  2.62612  3.00487  3.5656  2.76609  1.912
## 216 216   4  7.62857  2.62612  3.10478  6.7329  2.76609  2.678
## 217 217   4  1.31183  2.62612  2.49519  2.5241  2.76609  2.678
## 218 218   4  2.08652 -2.13105 -0.57007  0.2824 -2.07511 -0.415
## 219 219   4  2.10047  1.79703  2.29092  3.1390  2.76609  2.678
## 220 220   4  1.25590  0.98740  2.06578  2.3944  2.76609  1.385
## 221 221   4  0.92285  0.97754  1.56609  1.2983  0.91393  1.072
## 222 222   4  0.91941  1.59710  0.63041  2.2766  0.25343  0.672
## 223 223   4  2.10047  0.52761  2.31886  2.3944  2.81587  2.289
## 224 224   4  1.47114  0.52761  1.05176  1.1288  0.39705  1.013
## 225 225   4  7.62857  1.37306  4.05383  4.9742  0.49888  2.678
## 226 226   4  2.49535  1.47226  1.38433  3.9152  1.09141  1.131
## 227 227   4  0.91318  1.47226  2.60048  0.7384  2.81587  0.533
## 228 228   4  2.10047  1.47226  1.76955  3.8589  2.81587  2.862
## 229 229   4  0.70549  0.08803  1.06580  2.2547  0.49668  1.131
## 230 230   4  1.50945  0.80243  0.99388  0.9327  0.32860  0.954
## 231 231   4  1.90306  1.37005  1.25568  3.9152  0.22687  1.791
## 232 232   4  1.50813  1.37005  1.38433  1.1288  2.81587  0.835
## 233 233   4  0.92285  0.27080  0.28463  0.9327  0.49668  0.835
## 234 234   4 -0.06771  0.37804  0.99388  1.2983  1.69413 -0.201
## 235 235   4 -0.06008  1.10969  1.25568  0.4491  2.13933  0.105
## 236 236   4  1.90658  1.26317  3.10446  1.7562  1.34276  1.619
## 237 237   4 -0.07285 -2.13105 -0.43545  1.7533 -2.07511  0.081
## 238 238   4  0.16112  0.97754 -0.27061  1.2983  1.47470  0.656
## 239 239   4 -0.07285  1.13547 -0.48506  1.9283  0.08738  0.656
## 240 240   4  1.11403  2.16129  1.38433  3.4755  0.46154  2.066
## 241 241   4 -0.06008  0.98740  1.25568  1.4471  0.49668  1.205
## 242 242   4  1.11403  0.80243  2.99968  1.5953  2.81587  0.895
## 243 243   4  1.50813  0.97754 -0.19318  0.9327  1.69413  0.460
## 244 244   4  1.70570  1.79408  0.99388  2.3944  2.13933  1.925
## 245 245   4  2.10511  1.10667  1.38433  3.3617  2.76609  1.838
## 246 246   4  1.90306  1.59469  4.26715  2.9478  2.13933  2.862
## 247 247   4  1.10613  1.59469  2.31886  1.1288  0.91393  1.131
## 248 248   4  0.55334  0.44300  1.18890  0.3214  0.49668  0.266
## 249 249   4  4.02620  2.16129  1.25568  4.1443  0.63617  1.690
## 250 250   4  0.91318  0.64546  2.31886  0.7384  2.13933  1.131
## 251 251   4  2.49535  1.79703  0.99388  2.7908  2.13933  2.497
## 252 252   4  0.91318  0.38453  1.44201  3.3617  1.59642  1.044
## 253 253   4  2.49535  1.37005  3.23102  4.8625  0.46154  2.678
## 254 254   4  0.92285  2.62444  2.29092  0.8123  2.76609  2.497
## 255 255   4  0.55334  0.37804  0.99388  0.4491  0.91393  0.895
## 256 256   4  2.10046  0.38453  0.28463  1.9283  0.49000  0.637
## 257 257   4 -0.06771  0.32265  0.77927  0.5775  1.47470  0.835
## 258 258   4  1.47114  0.38453  0.98473  2.3944  2.81587  1.131
## 259 259   4  0.92285  1.47226  0.99388  2.0986  2.81587  1.190
## 260 260   4  2.49535  1.13547  4.16596  5.7607  1.34276  2.497
## 261 261   4  0.16112  0.44300  1.76955  0.4491  0.49668  0.656
## 262 262   4  0.91318  1.26317  1.76955  1.2983  0.32860  1.925
## 263 263   4  0.73621  1.37005  0.99388  2.6532  0.22687  1.429
## 264 264   4  2.49532  0.97754  0.82367  0.4491  0.49000  0.190
## 265 265   4  1.10613  0.80243  2.84597  1.4471  2.81587  1.554
## 266 266   4  2.49535  1.59710  1.82326  2.9478  2.76609  0.017
## 267 267   4  0.71711  0.52761  1.38433  1.5953  0.49668  0.017
## 268 268   4  1.70570  1.47470  1.25568  1.7562  0.25343  1.262
## 269 269   4  2.49535 -2.31339 -0.48506 -1.9956  0.57373 -1.021
## 270 270   4 -0.61744  0.44300 -0.48506  0.3214  0.32860 -1.021
## 271 271   4  1.11403  0.80243  1.56609  3.8589  0.22687  2.289
## 272 272   4  2.08652  0.94462  0.05155  0.3856  0.49000  0.925
## 273 273   4  7.62857  1.59710  3.10478  4.9742  0.25343  2.066
## 274 274   4  2.10511  1.26317  2.99968  2.6532  2.13933  1.838
## 275 275   4  1.50813  1.14217 -0.19318  0.4491  0.49888  0.840
## 276 276   4 -0.85401  0.37804  0.77927 -1.9956 -1.21148  1.190
## 277 277   4  4.02620  1.79408  1.56609  6.7329  2.13933  2.862
## 278 278   4  0.71711  0.97754  2.31886  0.7384  0.49668  0.266
## 279 279   4  0.71711  1.79408  0.99388  1.4471  0.53236  1.190
## 280 280   4  1.10613  1.47226  1.56609  2.0986  2.81587  2.497
## 281 281   4  1.10613  1.47470  2.29092  2.2547  2.76609  1.523
## 282 282   4 -0.06771  0.27080 -0.27061  0.7384  0.45707  0.835
## 283 283   4  2.10511  0.80243  1.76955  4.8625  0.40414  1.760
## 284 284   4  0.55334  1.26317 -0.27061  0.5775  0.57373  0.190
## 285 285   4  0.71711  0.80243  0.28463  0.9327  1.69413  1.013
## 286 286   4  1.50813  0.44300  0.77927 -0.9678 -0.83894  0.017
## 287 287   4  0.12190  0.30754 -0.61009  1.0245 -0.93074  0.450
## 288 288   4  4.02620  2.15818  1.56609  3.8589  2.81587  2.862
## 289 289   4  1.10613  0.97754  2.03379  2.5241  1.34276  1.491
## 290 290   4  2.10047  1.47470  1.44201  1.2983  2.76609  1.912
## 291 291   4  0.92285  0.44300  1.18890  1.7562  0.57373  0.190
## 292 292   4 -0.46680  0.16190 -0.27061 -1.9956 -1.21148 -1.021
## 293 293   4 -0.61744  0.27080  1.76955  0.5775  0.49668  0.017
## 294 294   4  4.02620  2.15818  1.56609  4.0414  2.81587  1.838
## 295 295   4  4.02620  2.62612  1.56609  4.1443  2.76609  1.838
## 296 296   4  2.10047  1.37005  1.56609  2.5241  1.22887  2.023
## 297 297   4  1.10613  1.26317  0.28463  0.3214  0.57373  0.656
## 298 298   4  1.31183  0.27080  0.77927  1.7562  0.51768  0.994
## 299 299   4  1.90210  1.37306  2.31886  0.8123  2.76609  1.912
## 300 300   4  0.32477  0.64546  0.28463  0.4491  0.49668  0.835
## 301 301   4 -0.06771  0.64546  0.77927  0.3214  0.40414  0.190
## 302 302   4  2.10047  1.47226  1.76955 -1.9956 -1.21148 -1.021
## 303 303   4  4.02620  1.59469  3.10446  2.7908  2.81587  2.289
## 304 304   4  1.70557  1.37005  2.99968  2.0986  2.76609  1.791
## 305 305   4  0.71711  0.37804  0.77927  0.4491  0.32860  0.954
## 306 306   4  2.49535  2.15818  4.37711  1.4471  0.08738  1.760
## 307 307   4  0.91318  1.13547  1.18890  1.2983  1.69413  0.656
## 308 308   4  1.10613  0.32265  2.60048  1.5953  0.57373 -0.499
## 309 309   4  0.92285  0.52761  2.03379  1.4471 -0.23622  0.470
## 310 310   4  2.08652  1.13547  0.28463  1.4471  0.49668  1.249
## 311 311   4  2.10511  1.47470  2.29092  1.4471  1.59642  0.585
## 312 312   4  1.90210  0.81420  1.25568  1.4471  0.53350  0.942
## 313 313   4  2.10511  1.26749  1.44201  1.2983  2.76609  1.912
## 314 314   4  2.10511  1.59710  2.29092  2.6532  2.76609  1.523
## 315 315   4  1.74936  1.59710  0.70239 -0.9678  0.53350  0.688
## 316 316   4  0.91318  1.47470 -0.40473  1.1288  2.76609  1.262
## 317 317   4  2.49535  0.98740  2.06578  3.3617  2.02749  1.838
## 318 318   4  2.49535  1.47470  1.44201  5.1640  1.11512  2.678
## 319 319   4  2.10047  1.37306  1.61888  1.9283  0.63826  1.791
## 320 320   4  2.49535  1.37005  1.61888  3.9152  2.76609  2.678
## 321 321   4  0.73621  1.14217  0.98473  1.0245  2.81587  1.112
## 322 322   4  1.11403  0.45037  1.25568  1.5953  2.02749  1.205
## 323 323   4  1.50813  0.98740  1.61888  2.0986  2.76609  1.912
## 324 324   4  4.02620  1.59710  1.25568  4.5405  1.59642  2.678
## 325 325   4  2.10047  1.47470  2.88578  3.9152  2.02749  2.678
## 326 326   4  2.10047  1.37306  1.82326  4.8625  2.76609  1.523
## 327 327   4  2.10047  1.59710  1.06580  3.9152  0.53350  1.690
## 328 328   4  2.10047  1.14217  1.82326  2.6532  0.75221  0.688
## 329 329   4  0.92285  0.65645  2.06578  1.9283  2.76609  2.284
## 330 330   4  0.11237  0.81420  1.25568  0.7384  0.53350  0.637
## 331 331   4  2.10511  2.16129  1.61888  2.3944  2.76609  1.791
## 332 332   4  2.10047  1.47470  0.82367  0.9327 -1.23243  1.097
## 333 333   4  2.49535  1.79408  1.38433  3.9727  1.34276  1.619
## 334 334   4  7.62857  1.14217  1.61888  6.7329  2.76609  2.284
## 335 335   4  1.10613  1.47470  1.61888  0.7384  0.41301  0.364
## 336 336   4  1.90210  1.26749  1.44201  2.3944  0.49888  0.790
## 337 337   4  2.49535  1.26749  1.61888  2.7908  2.76609  1.791
## 338 338   4  0.91318  1.26749 -0.40473  1.4471  1.34276  1.262
## 339 339   4  2.10047  2.62612  1.61888  2.3944  0.25343  2.284
## 340 340   4  1.11403  1.59710  2.88578  3.3617 -0.93074  2.678
## 341 341   4  2.10511  2.16129  4.29447  2.3944  2.76609  2.678
## 342 342   4  1.70557  1.14217  1.06580  4.8625  0.46154  2.066
## 343 343   4  2.49535  1.47470  1.61888  2.7908  2.76609  2.678
## 344 344   4  2.49535  1.25756  1.82326  2.0986  0.53350  0.533
```

```r
stripplot(imp, pch = 20, cex = 1.2)
```

![plot of chunk unnamed-chunk-4](./assignment3_files/figure-html/unnamed-chunk-41.png) 

```r
xyplot(imp, CA ~ CO | .imp, pch = 20, cex = 1.4)
```

![plot of chunk unnamed-chunk-4](./assignment3_files/figure-html/unnamed-chunk-42.png) 

##data1 - after multiple imputation before grade coding 0 and 1

```r
data1<-complete(imp)
head(data1)
```

```
##   ID AGE      CA      M      CO      NN     PR      G
## 1  1   3  0.5210 1.1747  1.0518  0.3856 0.8302  0.925
## 2  2   3  4.0262 1.5971  4.0538  6.7329 2.7661  2.678
## 3  3   3  0.9151 0.9446  1.8268  0.8123 0.3971  0.697
## 4  4   3  0.1262 0.9514 -0.6101 -0.2703 0.5188 -0.286
## 5  5   3  1.1137 1.0403  0.6304  0.6375 0.3281  0.221
## 6  6   3 -0.6289 1.1097  0.7024  0.2824 0.5746  0.620
```



##data2 - after multiple imputation after grade coding 0 and 1

```r
data2<-data1
data2$AGE <- ifelse(data2$AGE == 3, 0, 1)
head(data2)
```

```
##   ID AGE      CA      M      CO      NN     PR      G
## 1  1   0  0.5210 1.1747  1.0518  0.3856 0.8302  0.925
## 2  2   0  4.0262 1.5971  4.0538  6.7329 2.7661  2.678
## 3  3   0  0.9151 0.9446  1.8268  0.8123 0.3971  0.697
## 4  4   0  0.1262 0.9514 -0.6101 -0.2703 0.5188 -0.286
## 5  5   0  1.1137 1.0403  0.6304  0.6375 0.3281  0.221
## 6  6   0 -0.6289 1.1097  0.7024  0.2824 0.5746  0.620
```






#1. M1: Fit the hypothesized 1-factor 6-indicator CFA model described above to the data (initial model). Request Robust ML (MLR in Mplus) and specify information=expected (under analysis). Scale the latent factor by setting its variance to 1. Provide your Mplus syntax and path diagram. (3 points)

##a. Assess the overall model fit using the most commonly reported fit statistics. Please specify the criteria that you use to make a decision. (2 points)

##b. Assess the model component fit. Be sure to comment on all relevant components and specify the criteria, where applicable, that you use to make a decision. (2 points)

##c. Is the model identified? Specify the identification rule(s) you use and show how the models pass/fail the rule(s). Be sure to check the necessary t-rule and at least one sufficient rule. (2 points)

#2. M2: Propose an alternative model and assess its overall model fit. Justify your choice of the model and show your decision process. Request MLR with information=expected. Please include a diagram of your proposed model showing standardized estimates. (5 points)

##a. Compare the fit of this model to that of the initial model using proper model comparison statistics. (2 points)

##b. Is the model identified? Specify the identification rule(s) you use and show how the models pass/fail the rule(s). Be sure to check the necessary t-rule and at least one sufficient rule. (2 points)

#3.M3: Fit the hypothesized 1-factor CFA model allowing the errors of NN and CA to correlate. Request MLR with information=expected. Record the chi-square value, df, CFI, RMSEA, and SRMR. (2 points)

#4.M4: Recode AGE=3 into 0 and AGE=4 into 1. Fit a model to test if the 3-year group differs from the 4-year group on the latent variable MATH based on the M3 measurement model. Request MLR with information=expected. Provide a path diagram (3 points)

##a. Record the chi-square value, df, CFI, RMSEA, and SRMR. (1 point)

##b. Does the 3-year group appear to differ from the 4-year group on MATH? Support your answer with numerical results from your output. What is the standardized difference between the two age groups in MATH? (2 points)

##c. AGE is dichotomous in this exercise. Should it be declared to be categorical? Explain.(2 points)

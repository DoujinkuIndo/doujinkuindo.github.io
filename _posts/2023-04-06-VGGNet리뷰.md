---
layout: post
title: VGGNet
categories:
  - 논문 리뷰
tags:
  - 논문 리뷰
  - VGGNet
  - 딥러닝
  - 컴퓨터 비전
last_modified_at:

---
## VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGERECOGNITION, VGGNet

### **Abstract**
---
VGGNet은 2014년 이미지넷 챌린지 대회에서 2등을 한 모델이다. 같은 대회에서 GoogLeNet 모델이 1위를 차지했다. 

**VGGNet의 특징** 
      
    1. 이전의 모델들에 비해 레이어의 수를 크게 늘렸다.(16~19 weight layer)
    2. 3X3크기의 Convolution Filter만을 사용했다.

### **1. INTRODUCTION**
---
GPU의 발전에 따라 컨볼루션 네트워크(ConvNets)는 점점 발전해왔고, 다양한 관점으로 컨볼루션 네트워크를 발전시키려는 연구가 있었다. VGGNet에서는 네트워크의 구조에서 깊이에 중점을 가지고 연구를 진행했다.
VGGNet에서는 이전의 모델들보다 깊은 레이어를 구성할수 있었다.

    AlexNet(2012) : 8-layers
    VGGNet(2014) : 16~19-layers

이는 3X3크기의 필터만을 사용하여 네트워크를 구성하여 얻은 효과라고 저자들은 설명한다.

### **2. CONVNET CONFIGURATIONS**
---
#### 2.1 Architecture

훈련시에는 입력이미지로 224X224사이즈의 RGB이미지를 사용했다. 전처리 과정으로는 RGB값의 평균값을 각픽셀에 빼주는 방법만 사용했다. 이 입력이미지는 컨볼루션 필터가 쌓여있는 레이어들을 통과하게 되는데, 이 필터들은 모두 3X3 사이즈로 이루어저 있다.
3x3의 필터를 채택한 이유는 3x3필터가 상하좌우, 중간 등의 특징을 찾아낼 수 있는 가장 작은 사이즈이기 때문이라고 한다. 필터의 스트라이드, 패딩은 1의 크기를 적용했고, 이로인해 입력, 출력 사이즈는 같다. 5개의 맥스풀링층이 컨볼루션 레이어 사이에 적용되는데, 맥스풀링층은 2x2의 사이즈를 가지고, 2의 스트라이드를 가진다. 맥스풀링이 적용되면 이미지의 W, H가 반으로 줄어든다. 컨볼루션 레이어가 끝나면 3개층의 Fully-Connected 레이어가 적용된다. 앞의 두개의 층은 4096개의 노드를 가지고, 마지막 층은 1000개의 노드를 가지고, 소프트맥스 함수가 적용된다. 모든 은닉층이후에는 비선형함수로 ReLU함수가 적용된다. 

#### 2.2 Configurations

모델의 적절한 깊이를 찾아내기 위해 모델의 깊이를 다르게하여 A~E의 이름을 붙인 11~19개의 층의 모델을 설계하여 비교 실험을 진행한다. 각각의 모델에서 이미지는 맥스풀링층을 거칠때 마다 채널이 2배씩 증가하여 64->512의 채널 변화를 가진다.


#### 2.3 Discussion

**3x3 크기의 필터를 사용한 이유**


1. 더 많은 층을 쌓음으로써 더많은 비선형함수를 적용시킬 수 있다.

2. 같은 receptive field를 가지는데에 작은 필터를 사용하면 더많은 횟수를 사용 할 수있다.

**파라미터 수 계산**

    파라미터 수의 계산 = input의 채널수 X output의 채널수 X 필터의 크기
    2x3x3xC^2 = 18C^2, 5x5xC^2 = 25C^2
    3x3x3xC^2 = 27C^2, 7x7xC^2 = 49C^2


B, C, D 의 모델을 비교하면, B와C는 같은 receptive field를 가지지만, C가 1x1 레이어를 3개 더 가짐으로써 3번의 비선형함수를 더 적용했고, C와D는 같은 횟수의 비선형 함수를 적용했지만, D가 더 큰 receptive field를 가진다. 그리고 실험결과 B보다 C가, C보다 D가 더 높은 정확도를 가지므로, 저자들은 receptive field의 크기와 비선형 함수의 적용횟수가 정확도에 도움이 된다고 설명한다.

  

### **3. CLASSIFICATION FRAMEWORK**

#### 3.1 Training
Training의 세부사항들로는
- input image crop
- 256의 mini-batch
- 0.9의 momentum
- dropout 정규화 (p=0.5)
- 0.01의 초기 학습률 적용 후 학습 정체시마다 학습률 10으로 나누기
등을 적용시켰다.

가장 가벼운 A모델의 가중치를 랜덤으로 초기화 시키고 학습시킨 가중치를 이후의 모델의 1~4 번째 컨볼루션 레이어, FC레이어에 적용 시키는 **pre-initalisation** 기법을 적용시켰다.

image crop을 위해서 scale factor인 **S**의 사이즈로 이미지를 자르고 224x224의 크기로 다시 잘랐다.
S의 설정에는 두가지 방식을 적용시켰는데,
고정된 크기의 S를 활용하는 single-scale trainning 방식과, 주어진 범위에서 랜덤한 크기의 S를 활용하는 multi-scale trainning방식을 활용했다.
#### 3.2 Testing

테스트시에는 image crop을 적용하지 않는다. 이로인해 input image의 크기가 달라지게 되는데, FC layer를 7x7의 Fully-convolutional layers로 대체하고, average pool, sum pool을 통해 output의 사이즈를 맞춰준다.

### **4. CLASSIFICATION EXPERIMENTS**





### 5.

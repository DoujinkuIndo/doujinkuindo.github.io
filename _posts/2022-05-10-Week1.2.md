# **Week1-2 : NLU**

## **1. NLU : 언어를 이해한다**

- Understanding  == **기계(모델,프로그램)가 문법을 잘맞추고 문장이나 대화의 의미를 잘 알고있**다
    - Syntactic == 문법적으로 옳은 문장
    - Semantic == 문장의 의미
- 의미← 감정분석 (긍정/부정), 문장간유사도, 의도파악, 질문에대답, 추론, …

## 2. GLUE & SQuAD : 세계에서 가장 공신력있는 NLU 대회 (benchmark)”

- GLUE
    - 문법 (CoLA)
    - 감성분석 (SST)
    - 문장유사성 (STS,MRPC, QQP)
    - 추론 (MNLI,RTE)
    - 언급대상추론 (WNLI)
- SQuAD
    - QA
- GLUE ➡ superGLUE
    - Baseline: Bert
- SQuAD1.0 ➡ SQuAD2.0

![asdasd.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e530600c-5d1f-4c82-97d5-31b99a62f844/asdasd.png)

## 3. NLP task in real life : NLP task 실생활에서 사용

- 문법 (CoLA) ➡ 자동문법교정
- 감성분석 (SST) ➡ 상품&서비스리뷰데이터긍부정판별
- 문장유사성 (paraphrase) (STS,MRPC, QQP) ➡ 유사문서클러스터링(ex. Quora Question Pair Competition)
- 추론 (MNLI,RTE) ➡ 자동내부및회계감사
- 언급대상추론 (WNLI) ➡ QA, 요약, 번역등의성능향상을위해필수요 소
- QA (SQuAD) ➡ 검색시스템스닛펫

## 4. NLP task SOTA model :  NLP task 별 가장 우수한 모델

- GLUE
    - 문법➡ biLSTM, BERT(RoBERTa)
    - 감성분석➡ BERT(RoBERTa)
    - 문장유사성➡ Bert(RoBERTa)
    - 추론➡ T5, Bert(ALBERT, DeBERTa)
    - 언급대상추론 (WNLI) ➡ Bert(SpanBERT, RoBERTa)
- SQuAD
    - QA ➡ T5, Bert(Bigbird), XLNet

## 5. Applications :  Benchmark task 이외 NLU는어떻게 활용

- 분류➡  이탈고객예측, 상품 카테고리 분류, 위험 판별
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2821019d-0956-4069-9f04-69cbc44062b8/Untitled.png)
    
- 군집화➡ 유사제품군 군집화, 유사키 워드 생성
    - Vectorize ➡ distance (K-means)

---

## week1-2 과제

### 1. Paperswithcode([https://paperswithcode.com/task/natural-language-understanding](https://paperswithcode.com/task/natural-language-understanding))에서 NLU sub task 중 하나를 선택하여 본인 블로그에 정리해보세요. 아래 3가지 항목에 대해서 정리하세요. (각 항목 고려 사항 참고)

- NLU : 자연어 이해, 사람이 생성한 언어의 문법을 맞추거나, 의미를 파악한다.
- ****DialoGLUE :  7개의 task-oriented 대화 데이터셋,  온라인 뱅킹, 개인 비서, 레스토랑 예약, 등 다양한 대화 상황을 데이터로 가지고 있다.  csv와 json 의 자료형식을 가지고 있다.****
    - **ConvBERT : BERT을 개선한 모델, Span-based dynamic convolution**
    - MSLM (Masked Segmental Language ***Model)***

### 2. 팀원들의 게시글을 읽고 피드백 댓글을 달아보세요.

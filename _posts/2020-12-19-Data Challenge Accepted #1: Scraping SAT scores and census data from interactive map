Ever wanted to scrape the data from an interactive map to run some analyses of your own on it? Only to find that the map didn't have easy access to the data?

I did. Over at [Edgap](https://www.edgap.org/). While doing a lesson [To Explore, Understand, and Respond to Social Injustice](https://evanrushton.blogspot.com/2020/12/book-club-high-school-mathematics.html).

I could probably find a data store with the US SAT/ACT scores for a large number of schools from 2016 and then grab the census tract data and wrangle it until I could do the following analysis. However, I felt that I would learn something useful by trying to scrape the data from the interactive map.

# Scraping Data
I first tried inspecting elements to see if they were pulling from a defined file or url. No. Then I looked at the page source to see if there was an obvious script that was doing the work. Well, yes, but it was dynamically typing the url depending on the zoom window.

```js
function EdGapLayer() {
	SchoolDataLayer.call(this,'edgap', ZOOM_LEVEL_SCHOOL_TILES, ZOOM_LEVEL_SHOW_SCHOOL_TILES, getServer() + "csvs26/", ".csv");
}
```

So I figured I would grab the appropriate zoom window for the sample I want to analyze, and then look at the network output to look for anywhere that data was being loaded to use in the previous lines of code. Bingo, I found 3 json files and 1 csv. Upon inspection they were short lists... because a lot of the visualized data was already cached. So I cleared the browser cache and reloaded the same zoom window. This yielded quite a lot more files,

![screenshot of network panel](https://github.com/evanrushton/evanrushton.github.io/blob/master/images/edgap-network-2020-12-20.png)

# Merging Files
Here is the head of one of the csv files,

```csv
school_name,Type,OneYr,MRYear,roll,RollingYears,Notes,lat,lon,member,MAGNET_TEXT,CHARTER_TEXT,TOTFRL,DIRCERT,NSLP_STATUS
Frazier Mountain High,SAT,1040,2016,-1,-1,Note: California no longer releases SAT averages.,34.799506,-118.891645,,No,No,154,108,NSLPNO
Nordhoff High,SAT,1112,2016,-1,-1,Note: California no longer releases SAT averages.,34.442085,-119.266623,,No,No,324,201,NSLPNO
Carpinteria Senior High,SAT,1069,2016,-1,-1,Note: California no longer releases SAT averages.,34.410362,-119.516646,,No,No,338,152,NSLPNO
Fillmore Senior High,SAT,1022,2016,-1,-1,Note: California no longer releases SAT averages.,34.403654,-118.914785,,No,No,788,406,NSLPPRO2
Santa Paula High,SAT,978,2016,-1,-1,Note: California no longer releases SAT averages.,34.356329,-119.070484,,No,No,1386,660,NSLPCEO
```

Here is the head of one of the json files,

```json
{"type":"FeatureCollection","features":[{"geometry":{"type":"Polygon","coordinates":[[[-118.378222,34.643084],[-118.37779,34.64197],...,[-118.378222,34.643084]]]},"type":"Feature","properties":{"med_fam_inc":"92063","prop_children_married_fam":"0.729303548","pop_nat_amer":"0","pop":"5772","NAMELSAD10":"Census Tract 9201.02","pop_asian":"409","INTPTLAT10":"+34.6330733","prop_unemployed":"0.081774844","AWATER10":12194738.0,"TRACTCE10":"920102","pop_hl":"2032","prop_youth_disengage":"0.024752475","pop_black":"224","NAME10":"9201.02","ALAND10":615735934.0,"FUNCSTAT10":"S","prop_fam_below_1.85_pov":"0.232323232","COUNTYFP10":"037","enrolled_priv_school":"93","GEOID10":"06037920102","STATEFP10":"06","med_hh_inc":"69762","enrolled_pub_school":"1210","pop_white":"2960","prop_25_64_bach_or_higher":"0.345797188","MTFCC10":"G5020","INTPTLON10":"-118.6002393"}}]}
```

## Merge multiple csv files on the command line with awk 
(credit to [Marek Gra`c](https://apple.stackexchange.com/questions/80611/merging-multiple-csv-files-without-merging-the-header)),

```bash
$ awk '(NR == 1) || (FNR > 1)' file*.csv > bigfile.csv
```
json requires more finesse with jq. The jq 'keys' returns the fields of our json objects,

```bash
$ jq 'keys' 411.json
[
  "features",
  "type"
]
```

## Merge multiple json files on the command line with jq 
Credit to [Inian response to Satish](https://unix.stackexchange.com/questions/610461/how-to-merge-arrays-from-multiple-json-files-with-jq?rq=1)), 

```bash
$ jq -nc '{ features: [ inputs.features ] | add }' *.json > merged.json
```

## Checking Merged Files
To check that the csv merged properly I checked for one header row and counted all of the rows to be equal to the toal of the individual csvs and checked that the head and tail were correct. 

```bash
$ wc *.csv
       6      45     798 203 (1).csv
       8      61    1056 203 (2).csv
      20     181    2748 203 (3).csv
     139    1187   18256 204 (1).csv
      14     115    1854 204 (2).csv
     225    2372   32719 204 (3).csv
       2       9     249 205 (1).csv
      29     247    3830 205.csv
     436    4210   60656 merged.csv
     879    8427  122166 total
```
There are 4210 lines in merged.csv and the total lines are 8427. This makes sense because we removed 7 lines which were repeat header rows in the n-1 files that weren't the first file, leaving 8420, which is double the length of the merged file.

To check that the json merged I counted how many values the 'features' key had with `jq length`.
 
```bash
$ jq -r '.features | length' *.json 
2
30
18
2
2
11
48
38
26
6
13
74
219
806
261
160
43
6
686
507
133
2
137
114
6
1
4
1
3356
$ jq -r '.features | length' *.json | awk '{ SUM += $1} END { print SUM }'
6712
```
The merging appears to be successful. The last file in the directory has 3356 'features:' values which is the sum of the rest, given that 6712 is 2 * 3356. 

As another check I plotted a map of the data during exploration and checked that all rows were unique once they were in dataframes.

# Wrangling
Next I loaded these merged files in R to join the csv and json data into a dataframe for exploration and analysis.

## Loading Data
The csv and json files can be quickly loaded in R.

```R
schSAT <- read.csv("./Data/csv/merged.csv", header=TRUE) 
nhIncome <- fromJSON(file="./Data/json/merged.json")
```

## Joining Data
Each school row contains (lat, lon) that can be used to find the corresponding neighborhood from the polygons in the json file.
```R

```

Once the corresponding neighborhood is found, the additional properties can be joined for each school row.
```R

```

#Exploration
The question I am interested in is whether we can predict SAT scores with a given postal code or census tract.

Note: You are not a test score. I believe we should measure what we value, not arbitrarily value what we measure. However, this is a data challenge accepted. So even though SAT scores may be narrow metrics, they still make pretty graphs. Onward!

pretty graph 1

pretty graph 2

pretty graph 3

#Analysis
I threw many features into a model to see what was what and to look at interactions. ANOVA? ANCOVA? GLM?

Result 1

Result 2

Result 3

__ % of the variation in SAT scores is explained by median household income of the census tract the school is in. Correlation is not causation, but it does give one pause to consider why this might be true.

kop _crushton
 

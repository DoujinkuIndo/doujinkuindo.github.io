---
layout: post
title: "MIT 6.824 Raft Lab 2"
---
### Lab 2A
I have been following MIT 6.824 courses and built the lab following the requirement. It is a fun but not easy task. I record my thought and work in this blog. 
The first lab in this series is Lab 2 that need to build a raft concensus system. Lab 2A need to code the election process that you will make sure the system electect a leader even with network failure. 
Thinking what data need to be remembered for the raft: term and state as a minimum. 
(../images/raft-election.png "Raft state and RPC")
```go
type Raft struct {
	mu           sync.Mutex // Lock to protect shared access to this peer's state
	stateChanged *sync.Cond
	peers        []*labrpc.ClientEnd // RPC end points of all peers
	persister    *Persister          // Object to hold this peer's persisted state
	me           int                 // this peer's index into peers[]
	dead         int32               // set by Kill()

	logs              Log
	lastSnapshotIndex int
	lastSnapshotTerm  int
	currentTerm       int
	state             ServerState
	votedFor          int

	requestVoteDone bool
	commitId        int
	lastApplied     int

	stateSignal       *StateBroadcaster //a channel for state change that related to election and heart beat, raft state, etc
	startElectionAt   time.Time
	nextHeartbeatTime time.Time

	nextId  []int  // for each server, index of the next log entry to send to the server for replication
	matchId []int  //for each server, index of highest log entry know to be replicated on server
	hasVote []bool // for each server, vote result
	applyCh chan ApplyMsg

	// Your data here (2A, 2B, 2C).
	// Look at the paper's Figure 2 for a description of what
	// state a Raft server must maintain.

}

```

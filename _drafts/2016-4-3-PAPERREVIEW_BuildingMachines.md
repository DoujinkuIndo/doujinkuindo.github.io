---
layout: post
title: Review of Building Machines That Learn and Think Like People by Brenden Lake, Tomer Ullman, Joshua Tenenbaum and Samuel Gershman.
---

Intelligent machines should;

* build models of their environments that seek to explain causes, not just predict features.
* ground learning based in a fundamental understanding of physics (e.g. existence, persistence, ?) and psychology (agency and goals).
* deconstruct their knowledge into smaller discrete representations that can be composed together.
* learn to learn.


### Models

> We view learning as a form of model building, or explaining observed data through the construction of causal models of the world.

Almost all state-of-the-art neural networks algorithms are model-free. (not so sure about this I should figure it out for myself)

For example, convolutional neural networks for image recognition such as ??, deep Q networks for games such as AlphaGO, 

They predict, and recognise patterns, they do not explain, ??. 


### Foundations

##### Physics


##### Psychology


### Compositionally




# Comments to explore

> People can perceive a novel scene or spoken utterance in a fraction of a second, in what is surely a mostly feedforward process.

T

> A child watching someone play a new video game can infer that the avatar has agency and is trying to seek reward while avoiding punishment. This inference immediately constrains other inferences, allowing the child to infer what objects are good and what objects are bad.

How can a machine learn from another machine? I would love to explore this idea along transfer learning and ??

> The ‘child as scientist’ proposal further views the process of learning itself as also scientist-like, with recent experiments showing that children seek out new data to distinguish between hypotheses, isolate variables, test causal hypotheses, make use of the data-generating process in drawing conclusions, and learn selec- tively from others.

I would love to explore this idea along with active learning and falsification proposed in (Balduzzi, 201?). 

I feel like this sort of reasoning could be paired with reinforcement learning optimsing for information gained and ...? See ... my pseudocode

## Final thoughts, questions and notes

> In their influential textbook, Russell and Norvig (2003) state that “The quest for ‘artificial flight’ succeeded when the Wright brothers and others stopped imitating birds and started using wind tunnels and learning about aerodynamics.”

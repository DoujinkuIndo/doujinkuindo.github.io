---
layout: post
title: The 7D conv net
---

# Feature invatriance in new dimensions

Following on from my previous post on convolving over rotations (in the z axis), I want to expand on the idea of adding other dimensions to colvolve.

The motivation for this is; if we can make our features invariant to more irrelevant variables then we can learn faster, or from less data (as there are less parameters).  As we would have less parameters to learn. Thus we can build deeper nets with less width. Thus gaining 

For example. A face is still a face, regardless of its size, rotation, position, colour, if half of it is occluded, ...

### Position (x,y)

It is common practice to convolve over the two spatial dimensions of an image. The motivation being that the location of a feature, in an image, (e.g. face) does not effect whether or not it is that feature. (an assumption on the designers part)

### Rotation (z)

This idea is what inspired this line of thought and it makes a lot of sense to me. A face is still a face, regardless of whether it is upside down, or sideways...

### Scale (z)

Scale invariance would be a nice feature of a conv net. However, at first glance it seems very computationally expensive. 

So to make a feature of a different scale we would need to interpolate or remove weights from our kernels. Given the current architecture of 

Algorithm. 
Take kernel, K, of size 3x3 and map it onto a 6x6 weight space. Use the values of K and interpolate between them to fill in the new, larger kernel. 

### Rotation (x,y)



### Occlusion

Partial features.

### Colour


# Trade-off

Fundamentally, there is a trade off between the computations required for each kernel and the kernels invariance to irrelevant variables.

Which is better?

7D conv uses more computations. As it tests every possible orientation of a feature, whereas vanilla CNNs learn only features that are relevant...

But, having more convolutions would mean less parameters, thus less space is required? Although, having a SxOxCxRxNxdxnxn ...?

Also, how does having less parameters relate to optimisation in the sense of convexity?


# Attention

To solve the problem that this net would need more computations I think a good solution would be ...

Another net to decide when/which dimensions to colvolve for each kernel and image.

No point convolving over a feature that is already symmetric in that dimension. E.g. rotating a circle, or 